# Cloud TTS Integration Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Replace browser-based Web Speech API with OpenAI TTS API (tts-1-1106 model) for high-quality audio playback with server-side filesystem caching and LRU eviction.

**Architecture:** Client requests audio from new `/api/v1/tts` endpoint. Backend checks Postgres `audio_cache` table, returns cached MP3 files from `./cache/tts/` directory, or generates via OpenAI API. LRU cleanup runs before cache insertions when total size exceeds 500MB.

**Tech Stack:** FastAPI, OpenAI Python SDK, SQLModel (Postgres), Alembic (migrations), pytest

---

## Task 1: Database Migration - Audio Cache Table

**Files:**
- Create: `alembic/versions/<timestamp>_add_audio_cache_table.py`
- Reference: `doc/database.md`

**Step 1: Generate Alembic migration**

Run: `alembic revision -m "add audio cache table"`

Expected: New migration file created in `alembic/versions/`

**Step 2: Write migration up script**

Edit the generated migration file:

```python
"""add audio cache table

Revision ID: <auto-generated>
Revises: <previous-revision>
Create Date: <auto-generated>
"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import UUID

revision = '<auto-generated>'
down_revision = '<previous-revision>'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    op.create_table(
        'audio_cache',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('cache_key', sa.String(64), nullable=False),
        sa.Column('text', sa.String(1000), nullable=False),
        sa.Column('voice', sa.String(50), nullable=False),
        sa.Column('model', sa.String(50), nullable=False),
        sa.Column('file_size_bytes', sa.Integer(), nullable=False),
        sa.Column('file_path', sa.String(255), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('last_accessed_at', sa.DateTime(), nullable=False),
        sa.Column('access_count', sa.Integer(), nullable=False),
    )

    # Create indexes matching the naming convention in database.md
    op.create_index('audio_cache_pkey', 'audio_cache', ['id'], unique=True)
    op.create_index('ix_audio_cache_id', 'audio_cache', ['id'])
    op.create_index('ix_audio_cache_cache_key', 'audio_cache', ['cache_key'], unique=True)
    op.create_index('ix_audio_cache_last_accessed_at', 'audio_cache', ['last_accessed_at'])


def downgrade() -> None:
    op.drop_index('ix_audio_cache_last_accessed_at', table_name='audio_cache')
    op.drop_index('ix_audio_cache_cache_key', table_name='audio_cache')
    op.drop_index('ix_audio_cache_id', table_name='audio_cache')
    op.drop_index('audio_cache_pkey', table_name='audio_cache')
    op.drop_table('audio_cache')
```

**Step 3: Run migration locally**

Run: `alembic upgrade head`

Expected: Success message "Running upgrade ... -> <revision>, add audio cache table"

**Step 4: Update database schema documentation**

Edit `doc/database.md` and add the new table definition after the `cards` table:

```sql
CREATE TABLE "audio_cache" (
	"id" uuid PRIMARY KEY,
	"cache_key" varchar(64) NOT NULL,
	"text" varchar(1000) NOT NULL,
	"voice" varchar(50) NOT NULL,
	"model" varchar(50) NOT NULL,
	"file_size_bytes" integer NOT NULL,
	"file_path" varchar(255) NOT NULL,
	"created_at" timestamp NOT NULL,
	"last_accessed_at" timestamp NOT NULL,
	"access_count" integer NOT NULL
);
CREATE UNIQUE INDEX "audio_cache_pkey" ON "audio_cache" ("id");
CREATE INDEX "ix_audio_cache_id" ON "audio_cache" ("id");
CREATE UNIQUE INDEX "ix_audio_cache_cache_key" ON "audio_cache" ("cache_key");
CREATE INDEX "ix_audio_cache_last_accessed_at" ON "audio_cache" ("last_accessed_at");
```

**Step 5: Commit**

```bash
git add alembic/versions/*.py doc/database.md
git commit -m "feat: add audio_cache table for TTS caching

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 2: SQLModel - Audio Cache Model

**Files:**
- Create: `app/models/audio_cache.py`
- Modify: `app/models/__init__.py`

**Step 1: Write the AudioCache model**

Create `app/models/audio_cache.py`:

```python
import uuid
from datetime import datetime

from sqlmodel import Field, SQLModel


class AudioCache(SQLModel, table=True):
    """Audio cache for TTS responses."""

    __tablename__ = "audio_cache"

    id: uuid.UUID = Field(
        default_factory=uuid.uuid4,
        primary_key=True,
        index=True,
    )
    cache_key: str = Field(max_length=64, unique=True, index=True)
    text: str = Field(max_length=1000)
    voice: str = Field(max_length=50)
    model: str = Field(max_length=50)
    file_size_bytes: int
    file_path: str = Field(max_length=255)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    last_accessed_at: datetime = Field(default_factory=datetime.utcnow, index=True)
    access_count: int = Field(default=1)
```

**Step 2: Export model in __init__.py**

Edit `app/models/__init__.py` and add:

```python
from app.models.audio_cache import AudioCache

__all__ = ["AudioCache"]
```

**Step 3: Verify imports work**

Run: `python -c "from app.models import AudioCache; print('Import successful')"`

Expected: "Import successful"

**Step 4: Commit**

```bash
git add app/models/audio_cache.py app/models/__init__.py
git commit -m "feat: add AudioCache SQLModel

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 3: Configuration - OpenAI API Key

**Files:**
- Modify: `app/core/config.py`

**Step 1: Add TTS configuration to Settings**

Edit `app/core/config.py` and add these fields to the `Settings` class after the AI provider section:

```python
    # TTS Configuration
    tts_voice: str = "alloy"  # OpenAI TTS voice
    tts_model: str = "tts-1-1106"
    tts_cache_max_size_bytes: int = 524_288_000  # 500 MB
    tts_cache_dir: str = "./cache/tts"
```

**Step 2: Verify configuration loads**

Run: `python -c "from app.core.config import get_settings; s = get_settings(); print(f'TTS voice: {s.tts_voice}')"`

Expected: "TTS voice: alloy"

**Step 3: Create cache directory**

Run: `mkdir -p ./cache/tts`

Expected: Directory created

**Step 4: Add .gitignore entry**

Edit `.gitignore` and add:

```
# TTS audio cache
cache/
```

**Step 5: Commit**

```bash
git add app/core/config.py .gitignore
git commit -m "feat: add TTS configuration settings

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 4: Install OpenAI SDK Dependency

**Files:**
- Modify: `pyproject.toml`

**Step 1: Add OpenAI SDK to dependencies**

Edit `pyproject.toml` and add to the `dependencies` list:

```python
    # OpenAI TTS
    "openai>=1.57.0",
```

**Step 2: Install dependencies**

Run: `pip install -e .`

Expected: OpenAI package installed successfully

**Step 3: Verify installation**

Run: `python -c "import openai; print(f'OpenAI version: {openai.__version__}')"`

Expected: Version number printed (e.g., "OpenAI version: 1.57.0")

**Step 4: Commit**

```bash
git add pyproject.toml
git commit -m "feat: add OpenAI SDK dependency for TTS

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 5: TTS Service - Core Logic

**Files:**
- Create: `app/services/tts_service.py`
- Create: `tests/test_tts_service.py`

**Step 1: Write failing test for cache key generation**

Create `tests/test_tts_service.py`:

```python
import hashlib

import pytest

from app.services.tts_service import TTSService


def test_generate_cache_key():
    """Test cache key generation is deterministic and unique."""
    text1 = "Hello world"
    text2 = "Hello world"
    text3 = "Different text"
    voice = "alloy"
    model = "tts-1-1106"

    key1 = TTSService.generate_cache_key(text1, voice, model)
    key2 = TTSService.generate_cache_key(text2, voice, model)
    key3 = TTSService.generate_cache_key(text3, voice, model)

    # Same input = same key
    assert key1 == key2
    # Different input = different key
    assert key1 != key3
    # Key is SHA-256 hex (64 chars)
    assert len(key1) == 64
    assert all(c in '0123456789abcdef' for c in key1)
```

**Step 2: Run test to verify it fails**

Run: `pytest tests/test_tts_service.py::test_generate_cache_key -v`

Expected: FAIL with "ModuleNotFoundError: No module named 'app.services.tts_service'"

**Step 3: Write TTSService skeleton with generate_cache_key**

Create `app/services/tts_service.py`:

```python
import hashlib
import os
from datetime import datetime
from pathlib import Path
from uuid import UUID

from openai import OpenAI
from sqlmodel import Session, func, select

from app.core.config import get_settings
from app.models.audio_cache import AudioCache

settings = get_settings()


class TTSService:
    """Service for Text-to-Speech with caching."""

    def __init__(self, session: Session):
        self.session = session
        self.client = OpenAI(api_key=settings.openai_api_key)
        self.cache_dir = Path(settings.tts_cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    @staticmethod
    def generate_cache_key(text: str, voice: str, model: str) -> str:
        """Generate a deterministic cache key from text, voice, and model."""
        combined = f"{text}|{voice}|{model}"
        return hashlib.sha256(combined.encode()).hexdigest()
```

**Step 4: Run test to verify it passes**

Run: `pytest tests/test_tts_service.py::test_generate_cache_key -v`

Expected: PASS

**Step 5: Write failing test for get_cached_audio**

Add to `tests/test_tts_service.py`:

```python
from datetime import datetime, timedelta
from uuid import uuid4

from sqlmodel import Session

from app.models.audio_cache import AudioCache


def test_get_cached_audio_hit(session: Session):
    """Test cache hit updates last_accessed_at and access_count."""
    tts_service = TTSService(session)

    # Create cache entry
    cache_key = "test_key_123"
    cache_entry = AudioCache(
        id=uuid4(),
        cache_key=cache_key,
        text="Test text",
        voice="alloy",
        model="tts-1-1106",
        file_size_bytes=1024,
        file_path="cache/tts/test.mp3",
        created_at=datetime.utcnow() - timedelta(hours=1),
        last_accessed_at=datetime.utcnow() - timedelta(hours=1),
        access_count=1,
    )
    session.add(cache_entry)
    session.commit()

    # Get cached audio
    result = tts_service.get_cached_audio(cache_key)

    assert result is not None
    assert result.cache_key == cache_key
    assert result.access_count == 2
    # last_accessed_at should be updated (within 5 seconds of now)
    assert (datetime.utcnow() - result.last_accessed_at).total_seconds() < 5


def test_get_cached_audio_miss(session: Session):
    """Test cache miss returns None."""
    tts_service = TTSService(session)
    result = tts_service.get_cached_audio("nonexistent_key")
    assert result is None
```

**Step 6: Run test to verify it fails**

Run: `pytest tests/test_tts_service.py::test_get_cached_audio_hit -v`

Expected: FAIL with "AttributeError: 'TTSService' object has no attribute 'get_cached_audio'"

**Step 7: Implement get_cached_audio method**

Add to `app/services/tts_service.py`:

```python
    def get_cached_audio(self, cache_key: str) -> AudioCache | None:
        """Get cached audio entry and update access metadata."""
        statement = select(AudioCache).where(AudioCache.cache_key == cache_key)
        cache_entry = self.session.exec(statement).first()

        if cache_entry:
            # Update access metadata
            cache_entry.last_accessed_at = datetime.utcnow()
            cache_entry.access_count += 1
            self.session.add(cache_entry)
            self.session.commit()
            self.session.refresh(cache_entry)

        return cache_entry
```

**Step 8: Run tests to verify they pass**

Run: `pytest tests/test_tts_service.py -v`

Expected: All tests PASS

**Step 9: Commit**

```bash
git add app/services/tts_service.py tests/test_tts_service.py
git commit -m "feat: add TTSService with cache key generation and lookup

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 6: TTS Service - LRU Cleanup Logic

**Files:**
- Modify: `app/services/tts_service.py`
- Modify: `tests/test_tts_service.py`

**Step 1: Write failing test for cleanup**

Add to `tests/test_tts_service.py`:

```python
import tempfile
from pathlib import Path


def test_cleanup_old_cache_entries(session: Session):
    """Test LRU cleanup removes oldest entries when over size limit."""
    # Create temp directory for test
    with tempfile.TemporaryDirectory() as tmpdir:
        # Override cache dir for test
        from app.core.config import get_settings
        settings = get_settings()
        original_cache_dir = settings.tts_cache_dir
        original_max_size = settings.tts_cache_max_size_bytes
        settings.tts_cache_dir = tmpdir
        settings.tts_cache_max_size_bytes = 2000  # 2KB limit

        tts_service = TTSService(session)
        cache_dir = Path(tmpdir)

        # Create 3 cache entries with files (1KB each = 3KB total)
        for i in range(3):
            cache_key = f"key_{i}"
            file_path = cache_dir / f"{cache_key}.mp3"
            file_path.write_bytes(b"x" * 1024)  # 1KB file

            cache_entry = AudioCache(
                id=uuid4(),
                cache_key=cache_key,
                text=f"Text {i}",
                voice="alloy",
                model="tts-1-1106",
                file_size_bytes=1024,
                file_path=str(file_path),
                created_at=datetime.utcnow() - timedelta(hours=3-i),
                last_accessed_at=datetime.utcnow() - timedelta(hours=3-i),
                access_count=1,
            )
            session.add(cache_entry)
        session.commit()

        # Run cleanup (should remove oldest entry to get under 2KB)
        tts_service.cleanup_old_cache_entries()

        # Verify oldest entry is removed
        remaining = session.exec(select(AudioCache)).all()
        assert len(remaining) == 2
        assert all(e.cache_key != "key_0" for e in remaining)

        # Verify file was deleted
        assert not (cache_dir / "key_0.mp3").exists()
        assert (cache_dir / "key_1.mp3").exists()
        assert (cache_dir / "key_2.mp3").exists()

        # Restore settings
        settings.tts_cache_dir = original_cache_dir
        settings.tts_cache_max_size_bytes = original_max_size
```

**Step 2: Run test to verify it fails**

Run: `pytest tests/test_tts_service.py::test_cleanup_old_cache_entries -v`

Expected: FAIL with "AttributeError: 'TTSService' object has no attribute 'cleanup_old_cache_entries'"

**Step 3: Implement cleanup_old_cache_entries method**

Add to `app/services/tts_service.py`:

```python
    def cleanup_old_cache_entries(self) -> None:
        """Remove least recently used cache entries to stay under size limit."""
        # Calculate total cache size
        total_size_stmt = select(func.sum(AudioCache.file_size_bytes))
        total_size = self.session.exec(total_size_stmt).one() or 0

        if total_size <= settings.tts_cache_max_size_bytes:
            return  # Under limit, no cleanup needed

        # Calculate how much to remove
        size_to_remove = total_size - settings.tts_cache_max_size_bytes
        removed_size = 0

        # Get oldest entries by last_accessed_at
        stmt = select(AudioCache).order_by(AudioCache.last_accessed_at.asc())
        old_entries = self.session.exec(stmt).all()

        for entry in old_entries:
            if removed_size >= size_to_remove:
                break

            # Delete file from filesystem
            file_path = Path(entry.file_path)
            if file_path.exists():
                file_path.unlink()

            # Delete database record
            self.session.delete(entry)
            removed_size += entry.file_size_bytes

        self.session.commit()
```

**Step 4: Run test to verify it passes**

Run: `pytest tests/test_tts_service.py::test_cleanup_old_cache_entries -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/services/tts_service.py tests/test_tts_service.py
git commit -m "feat: add LRU cache cleanup for TTS

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 7: TTS Service - OpenAI API Integration

**Files:**
- Modify: `app/services/tts_service.py`
- Modify: `tests/test_tts_service.py`

**Step 1: Write failing test for generate_and_cache**

Add to `tests/test_tts_service.py`:

```python
from unittest.mock import Mock, patch


def test_generate_and_cache_audio(session: Session):
    """Test generating audio via OpenAI and caching it."""
    with tempfile.TemporaryDirectory() as tmpdir:
        from app.core.config import get_settings
        settings = get_settings()
        original_cache_dir = settings.tts_cache_dir
        settings.tts_cache_dir = tmpdir

        tts_service = TTSService(session)

        # Mock OpenAI API response
        mock_audio_data = b"fake_mp3_audio_data"
        mock_response = Mock()
        mock_response.content = mock_audio_data

        with patch.object(tts_service.client.audio.speech, 'create', return_value=mock_response):
            text = "Hello world"
            voice = "alloy"
            model = "tts-1-1106"

            result = tts_service.generate_and_cache_audio(text, voice, model)

            # Verify cache entry created
            assert result.text == text
            assert result.voice == voice
            assert result.model == model
            assert result.file_size_bytes == len(mock_audio_data)
            assert result.access_count == 1

            # Verify file exists
            file_path = Path(result.file_path)
            assert file_path.exists()
            assert file_path.read_bytes() == mock_audio_data

        settings.tts_cache_dir = original_cache_dir
```

**Step 2: Run test to verify it fails**

Run: `pytest tests/test_tts_service.py::test_generate_and_cache_audio -v`

Expected: FAIL with "AttributeError: 'TTSService' object has no attribute 'generate_and_cache_audio'"

**Step 3: Implement generate_and_cache_audio method**

Add to `app/services/tts_service.py`:

```python
    def generate_and_cache_audio(self, text: str, voice: str, model: str) -> AudioCache:
        """Generate audio via OpenAI TTS API and cache it."""
        # Run cleanup before adding new entry
        self.cleanup_old_cache_entries()

        # Generate cache key and file path
        cache_key = self.generate_cache_key(text, voice, model)
        file_path = self.cache_dir / f"{cache_key}.mp3"

        # Call OpenAI TTS API
        response = self.client.audio.speech.create(
            model=model,
            voice=voice,
            input=text,
        )

        # Save audio to file
        audio_data = response.content
        file_path.write_bytes(audio_data)

        # Create cache entry
        cache_entry = AudioCache(
            cache_key=cache_key,
            text=text,
            voice=voice,
            model=model,
            file_size_bytes=len(audio_data),
            file_path=str(file_path),
        )
        self.session.add(cache_entry)
        self.session.commit()
        self.session.refresh(cache_entry)

        return cache_entry
```

**Step 4: Run test to verify it passes**

Run: `pytest tests/test_tts_service.py::test_generate_and_cache_audio -v`

Expected: PASS

**Step 5: Write high-level get_audio test**

Add to `tests/test_tts_service.py`:

```python
def test_get_audio_end_to_end(session: Session):
    """Test complete flow: cache miss, generate, cache hit."""
    with tempfile.TemporaryDirectory() as tmpdir:
        from app.core.config import get_settings
        settings = get_settings()
        original_cache_dir = settings.tts_cache_dir
        settings.tts_cache_dir = tmpdir

        tts_service = TTSService(session)

        mock_audio_data = b"fake_audio"
        mock_response = Mock()
        mock_response.content = mock_audio_data

        with patch.object(tts_service.client.audio.speech, 'create', return_value=mock_response) as mock_create:
            text = "Test sentence"

            # First call: cache miss, should call OpenAI
            audio1 = tts_service.get_audio(text)
            assert audio1 is not None
            assert mock_create.call_count == 1

            # Second call: cache hit, should NOT call OpenAI
            audio2 = tts_service.get_audio(text)
            assert audio2 is not None
            assert mock_create.call_count == 1  # Still 1, not called again

            # Access count incremented
            cache_entry = session.exec(
                select(AudioCache).where(AudioCache.text == text)
            ).first()
            assert cache_entry.access_count == 2

        settings.tts_cache_dir = original_cache_dir
```

**Step 6: Run test to verify it fails**

Run: `pytest tests/test_tts_service.py::test_get_audio_end_to_end -v`

Expected: FAIL with "AttributeError: 'TTSService' object has no attribute 'get_audio'"

**Step 7: Implement get_audio method**

Add to `app/services/tts_service.py`:

```python
    def get_audio(self, text: str, voice: str | None = None, model: str | None = None) -> AudioCache:
        """Get audio for text (from cache or generate new)."""
        voice = voice or settings.tts_voice
        model = model or settings.tts_model

        # Check cache first
        cache_key = self.generate_cache_key(text, voice, model)
        cache_entry = self.get_cached_audio(cache_key)

        if cache_entry:
            return cache_entry

        # Cache miss: generate and cache
        return self.generate_and_cache_audio(text, voice, model)
```

**Step 8: Run all tests to verify they pass**

Run: `pytest tests/test_tts_service.py -v`

Expected: All tests PASS

**Step 9: Commit**

```bash
git add app/services/tts_service.py tests/test_tts_service.py
git commit -m "feat: add OpenAI TTS integration with caching

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 8: API Schema - TTS Request/Response

**Files:**
- Create: `app/schemas/tts.py`

**Step 1: Write TTS schemas**

Create `app/schemas/tts.py`:

```python
from pydantic import BaseModel, Field


class TTSRequest(BaseModel):
    """Request schema for TTS endpoint."""

    text: str = Field(..., max_length=1000, description="Text to convert to speech")
    voice: str | None = Field(None, max_length=50, description="Voice to use (default: alloy)")
    model: str | None = Field(None, max_length=50, description="Model to use (default: tts-1-1106)")


class TTSResponse(BaseModel):
    """Response schema for TTS endpoint."""

    cache_key: str = Field(..., description="Cache key for the audio")
    cached: bool = Field(..., description="Whether audio was from cache")
```

**Step 2: Verify imports**

Run: `python -c "from app.schemas.tts import TTSRequest, TTSResponse; print('Import successful')"`

Expected: "Import successful"

**Step 3: Commit**

```bash
git add app/schemas/tts.py
git commit -m "feat: add TTS API schemas

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 9: API Endpoint - TTS Route

**Files:**
- Create: `app/api/v1/tts.py`
- Modify: `app/api/router.py`
- Create: `tests/test_tts_api.py`

**Step 1: Write failing test for TTS endpoint**

Create `tests/test_tts_api.py`:

```python
from unittest.mock import Mock, patch

import pytest
from fastapi.testclient import TestClient


def test_tts_endpoint_generates_audio(client: TestClient, auth_headers: dict):
    """Test TTS endpoint generates audio and returns file."""
    with patch('app.services.tts_service.TTSService.get_audio') as mock_get_audio:
        # Mock return value
        mock_cache_entry = Mock()
        mock_cache_entry.cache_key = "test_key_abc123"
        mock_cache_entry.file_path = "cache/tts/test.mp3"
        mock_cache_entry.access_count = 1
        mock_get_audio.return_value = mock_cache_entry

        # Create fake audio file
        import tempfile
        from pathlib import Path
        with tempfile.TemporaryDirectory() as tmpdir:
            fake_file = Path(tmpdir) / "test.mp3"
            fake_file.write_bytes(b"fake_audio_data")
            mock_cache_entry.file_path = str(fake_file)

            response = client.post(
                "/api/v1/tts",
                json={"text": "Hello world"},
                headers=auth_headers,
            )

            assert response.status_code == 200
            assert response.headers["content-type"] == "audio/mpeg"
            assert response.content == b"fake_audio_data"


def test_tts_endpoint_requires_auth(client: TestClient):
    """Test TTS endpoint requires authentication."""
    response = client.post("/api/v1/tts", json={"text": "Hello"})
    assert response.status_code == 401


def test_tts_endpoint_validates_text_length(client: TestClient, auth_headers: dict):
    """Test TTS endpoint validates text length."""
    long_text = "x" * 1001  # Over 1000 char limit
    response = client.post(
        "/api/v1/tts",
        json={"text": long_text},
        headers=auth_headers,
    )
    assert response.status_code == 422
```

**Step 2: Run test to verify it fails**

Run: `pytest tests/test_tts_api.py::test_tts_endpoint_generates_audio -v`

Expected: FAIL with "404 Not Found"

**Step 3: Implement TTS endpoint**

Create `app/api/v1/tts.py`:

```python
from pathlib import Path
from typing import Annotated

from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import FileResponse
from sqlmodel import Session

from app.core.database import get_session
from app.dependencies import CurrentUser
from app.schemas.tts import TTSRequest
from app.services.tts_service import TTSService

router = APIRouter(prefix="/tts", tags=["TTS"])


@router.post("", response_class=FileResponse)
async def generate_speech(
    request: TTSRequest,
    current_user: CurrentUser,
    session: Annotated[Session, Depends(get_session)],
) -> FileResponse:
    """
    Generate speech audio for the given text.

    Returns MP3 audio file. Uses cached audio if available, otherwise generates via OpenAI TTS.
    """
    tts_service = TTSService(session)

    try:
        cache_entry = tts_service.get_audio(
            text=request.text,
            voice=request.voice,
            model=request.model,
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate audio: {str(e)}",
        )

    file_path = Path(cache_entry.file_path)
    if not file_path.exists():
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Audio file not found",
        )

    return FileResponse(
        path=file_path,
        media_type="audio/mpeg",
        filename=f"{cache_entry.cache_key}.mp3",
    )
```

**Step 4: Register router**

Edit `app/api/router.py` and add:

```python
from app.api.v1 import auth, cards, generate, health, tags, tts, users

# Add to router includes:
api_router.include_router(tts.router)
```

**Step 5: Run tests to verify they pass**

Run: `pytest tests/test_tts_api.py -v`

Expected: All tests PASS

**Step 6: Commit**

```bash
git add app/api/v1/tts.py app/api/router.py tests/test_tts_api.py
git commit -m "feat: add TTS API endpoint

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 10: Frontend - TTS API Client

**Files:**
- Modify: `frontend/src/services/api.ts`

**Step 1: Add TTS API client function**

Edit `frontend/src/services/api.ts` and add after the `generateApi` section:

```typescript
// TTS API
export const ttsApi = {
  generateAudio: async (text: string): Promise<Blob> => {
    const response = await api.post('/tts',
      { text },
      { responseType: 'blob' }
    );
    return response.data;
  },
};
```

**Step 2: Test in browser console (manual verification)**

After backend is running:
1. Start backend: `uvicorn app.main:app --reload`
2. Start frontend: `cd frontend && npm run dev`
3. Open browser console and test:

```javascript
// This is a manual test to verify the API call works
// Login first, then:
const { ttsApi } = await import('./services/api.ts');
const blob = await ttsApi.generateAudio("Hello world");
console.log('Audio blob size:', blob.size);
```

Expected: No errors, blob size > 0

**Step 3: Commit**

```bash
git add frontend/src/services/api.ts
git commit -m "feat: add TTS API client function

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 11: Frontend - Replace Web Speech API with Cloud TTS

**Files:**
- Modify: `frontend/src/components/FlashcardDisplay.tsx`

**Step 1: Add audio caching and playback state**

Edit `frontend/src/components/FlashcardDisplay.tsx`. Replace the `speakText` function and add audio state:

```typescript
import { Box, Typography, Card as MuiCard, CardContent, IconButton, Chip } from '@mui/material';
import { useState, useEffect, useCallback, useRef } from 'react';
import VolumeUpIcon from '@mui/icons-material/VolumeUp';
import type { Card } from '../services/api';
import { ttsApi } from '../services/api';

interface FlashcardDisplayProps {
  card: Card;
  isFlipped: boolean;
  onFlip: () => void;
}

export default function FlashcardDisplay({ card, isFlipped, onFlip }: FlashcardDisplayProps) {
  const [autoPlayEnabled, setAutoPlayEnabled] = useState(() => {
    return localStorage.getItem('autoPlayAudio') === 'true';
  });

  const audioRef = useRef<HTMLAudioElement | null>(null);
  const audioCacheRef = useRef<Map<string, string>>(new Map()); // text -> blob URL

  const toggleAutoPlay = (e: React.MouseEvent) => {
    e.stopPropagation();
    const newValue = !autoPlayEnabled;
    setAutoPlayEnabled(newValue);
    localStorage.setItem('autoPlayAudio', String(newValue));
  };

  const speakText = useCallback(async (text: string) => {
    try {
      // Stop any currently playing audio
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }

      // Check cache first
      let audioUrl = audioCacheRef.current.get(text);

      if (!audioUrl) {
        // Fetch from API
        const blob = await ttsApi.generateAudio(text);
        audioUrl = URL.createObjectURL(blob);
        audioCacheRef.current.set(text, audioUrl);
      }

      // Play audio
      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      await audio.play();
    } catch (error) {
      console.error('Failed to play audio:', error);
      // Fallback to Web Speech API if TTS fails
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      utterance.rate = 0.9;
      window.speechSynthesis.speak(utterance);
    }
  }, []);

  // Cleanup blob URLs on unmount
  useEffect(() => {
    return () => {
      audioCacheRef.current.forEach((url) => URL.revokeObjectURL(url));
      audioCacheRef.current.clear();
    };
  }, []);

  // Handle auto-play when flipped
  useEffect(() => {
    if (isFlipped && autoPlayEnabled) {
      const timer = setTimeout(() => {
        speakText(card.context_sentence);
      }, 300);
      return () => clearTimeout(timer);
    }
  }, [isFlipped, autoPlayEnabled, card.context_sentence, speakText]);
```

**Step 2: Update manual play button click handler**

Find the IconButton with VolumeUpIcon in the "Back Content" section (around line 133-142) and update the onClick handler:

```typescript
          <IconButton
            sx={{ mt: 2 }}
            onClick={(e) => {
              e.stopPropagation();
              speakText(card.context_sentence);
            }}
            color="primary"
          >
            <VolumeUpIcon />
          </IconButton>
```

**Step 3: Test in browser**

Manual test:
1. Start backend: `uvicorn app.main:app --reload`
2. Start frontend: `cd frontend && npm run dev`
3. Login and go to Study page
4. Flip a card - should hear cloud TTS audio (not browser TTS)
5. Click speaker icon - should replay audio
6. Toggle auto-play and verify it works

Expected: High-quality audio plays from OpenAI TTS instead of robotic browser voice

**Step 4: Commit**

```bash
git add frontend/src/components/FlashcardDisplay.tsx
git commit -m "feat: replace Web Speech API with Cloud TTS

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 12: Integration Testing

**Files:**
- Create: `tests/test_tts_integration.py`

**Step 1: Write integration test**

Create `tests/test_tts_integration.py`:

```python
import os
from pathlib import Path

import pytest
from fastapi.testclient import TestClient


@pytest.mark.skipif(
    not os.getenv("OPENAI_API_KEY"),
    reason="OpenAI API key not set"
)
def test_tts_full_integration(client: TestClient, auth_headers: dict):
    """
    Full integration test with real OpenAI API.

    This test is skipped unless OPENAI_API_KEY is set in environment.
    """
    # First request - should call OpenAI API
    response1 = client.post(
        "/api/v1/tts",
        json={"text": "Integration test audio"},
        headers=auth_headers,
    )

    assert response1.status_code == 200
    assert response1.headers["content-type"] == "audio/mpeg"
    assert len(response1.content) > 0
    audio_size_1 = len(response1.content)

    # Second request - should use cache
    response2 = client.post(
        "/api/v1/tts",
        json={"text": "Integration test audio"},
        headers=auth_headers,
    )

    assert response2.status_code == 200
    assert len(response2.content) == audio_size_1  # Same audio

    # Different text - should call API again
    response3 = client.post(
        "/api/v1/tts",
        json={"text": "Different text here"},
        headers=auth_headers,
    )

    assert response3.status_code == 200
    assert len(response3.content) > 0
    assert len(response3.content) != audio_size_1  # Different audio


def test_tts_cache_persistence(client: TestClient, auth_headers: dict):
    """Test that cached audio persists across service instances."""
    from unittest.mock import Mock, patch

    # Mock OpenAI to avoid real API calls
    mock_audio = b"test_audio_data"
    mock_response = Mock()
    mock_response.content = mock_audio

    with patch('openai.OpenAI') as mock_openai:
        mock_client = Mock()
        mock_openai.return_value = mock_client
        mock_client.audio.speech.create.return_value = mock_response

        # First request
        response1 = client.post(
            "/api/v1/tts",
            json={"text": "Persistence test"},
            headers=auth_headers,
        )
        assert response1.status_code == 200

        # Verify OpenAI was called once
        assert mock_client.audio.speech.create.call_count == 1

        # Second request (should use cache, not call OpenAI again)
        response2 = client.post(
            "/api/v1/tts",
            json={"text": "Persistence test"},
            headers=auth_headers,
        )
        assert response2.status_code == 200

        # Verify OpenAI was NOT called again
        assert mock_client.audio.speech.create.call_count == 1
```

**Step 2: Run integration tests**

Run: `pytest tests/test_tts_integration.py -v`

Expected: Tests PASS (first test skipped if no API key)

**Step 3: Run full test suite**

Run: `pytest -v`

Expected: All tests PASS

**Step 4: Commit**

```bash
git add tests/test_tts_integration.py
git commit -m "test: add TTS integration tests

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 13: Documentation

**Files:**
- Create: `docs/tts-implementation.md`
- Modify: `README.md`

**Step 1: Write implementation documentation**

Create `docs/tts-implementation.md`:

```markdown
# Cloud TTS Implementation

## Overview

This project uses OpenAI's TTS API (model: `tts-1-1106`) to generate high-quality audio pronunciation for flashcards.

## Architecture

### Backend
- **Endpoint:** `POST /api/v1/tts`
- **Service:** `TTSService` in `app/services/tts_service.py`
- **Cache:** Postgres `audio_cache` table + filesystem at `./cache/tts/`
- **LRU Eviction:** Automatic cleanup when cache exceeds 500MB

### Frontend
- **Component:** `FlashcardDisplay.tsx`
- **Client:** `ttsApi.generateAudio()` in `services/api.ts`
- **Cache:** In-memory blob URLs (per session)

## Configuration

Add to `.env`:

```env
OPENAI_API_KEY=sk-...
TTS_VOICE=alloy
TTS_MODEL=tts-1-1106
TTS_CACHE_MAX_SIZE_BYTES=524288000
TTS_CACHE_DIR=./cache/tts
```

## Cache Strategy

**Server-Side:**
- Audio files stored as `./cache/tts/{sha256_hash}.mp3`
- Metadata in `audio_cache` table (cache_key, file_size, last_accessed_at, etc.)
- LRU cleanup removes oldest files when total size > 500MB

**Client-Side:**
- Blob URLs cached in memory per session
- Cleanup on component unmount

## API Costs

OpenAI TTS pricing: ~$0.015 per 1,000 characters

Typical card sentence: 50-100 characters = $0.0015 per card
With caching, cost is paid only once per unique sentence.

## Testing

```bash
# Unit tests
pytest tests/test_tts_service.py -v

# API tests
pytest tests/test_tts_api.py -v

# Integration tests (requires OPENAI_API_KEY)
OPENAI_API_KEY=sk-... pytest tests/test_tts_integration.py -v
```

## Fallback Behavior

If TTS API fails, frontend falls back to Web Speech API (browser TTS).
```

**Step 2: Update main README**

Edit `README.md` and add to the Features section:

```markdown
- **Cloud TTS:** High-quality audio pronunciation using OpenAI TTS API with intelligent server-side caching
```

Add to Environment Variables section:

```markdown
- `OPENAI_API_KEY`: OpenAI API key (required for TTS)
- `TTS_VOICE`: Voice for TTS (default: "alloy")
- `TTS_MODEL`: TTS model (default: "tts-1-1106")
```

**Step 3: Commit**

```bash
git add docs/tts-implementation.md README.md
git commit -m "docs: add TTS implementation documentation

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 14: Deployment Preparation

**Files:**
- Create: `.env.example`
- Modify: `doc/database.md` (if not already updated)

**Step 1: Update .env.example**

Edit `.env.example` (or create if missing) and add:

```env
# OpenAI TTS
OPENAI_API_KEY=sk-your-openai-api-key-here
TTS_VOICE=alloy
TTS_MODEL=tts-1-1106
TTS_CACHE_MAX_SIZE_BYTES=524288000
TTS_CACHE_DIR=./cache/tts
```

**Step 2: Verify cache directory in .gitignore**

Run: `grep -q "cache/" .gitignore && echo "Already ignored" || echo "cache/" >> .gitignore`

Expected: "Already ignored" (added in Task 3)

**Step 3: Create deployment checklist**

Create `docs/deployment-checklist.md`:

```markdown
# TTS Feature Deployment Checklist

## Pre-Deployment

- [ ] Run all tests: `pytest -v`
- [ ] Set `OPENAI_API_KEY` in production environment
- [ ] Create cache directory: `mkdir -p ./cache/tts`
- [ ] Ensure cache directory has write permissions
- [ ] Run database migration: `alembic upgrade head`
- [ ] Verify OpenAI API key has TTS permissions

## Post-Deployment

- [ ] Test TTS endpoint: `curl -X POST /api/v1/tts -d '{"text":"test"}'`
- [ ] Monitor cache size: `du -sh ./cache/tts`
- [ ] Check Postgres `audio_cache` table has entries
- [ ] Verify LRU cleanup runs when cache exceeds 500MB
- [ ] Test frontend audio playback on Study page

## Monitoring

- Watch OpenAI API usage in OpenAI dashboard
- Monitor cache disk usage
- Check `audio_cache` table growth in Postgres
```

**Step 4: Commit**

```bash
git add .env.example docs/deployment-checklist.md .gitignore
git commit -m "chore: add deployment preparation for TTS

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Final Verification

**Step 1: Run complete test suite**

Run: `pytest -v --cov=app`

Expected: All tests pass, good coverage

**Step 2: Start backend and verify endpoints**

Run: `uvicorn app.main:app --reload`

Visit: `http://localhost:8000/api/v1/docs`

Expected: `/api/v1/tts` endpoint visible in docs

**Step 3: Manual frontend test**

1. Start frontend: `cd frontend && npm run dev`
2. Login to app
3. Go to Study page
4. Flip a card
5. Verify cloud TTS audio plays (high quality)
6. Click speaker icon to replay
7. Toggle auto-play off/on

Expected: Smooth, high-quality audio playback

**Step 4: Verify cache behavior**

```bash
# Check cache directory
ls -lh cache/tts/

# Check database
psql $DATABASE_URL -c "SELECT cache_key, file_size_bytes, access_count FROM audio_cache LIMIT 5;"
```

Expected: Audio files present, database records match

---

## Summary

This plan implements cloud TTS with:
- ✅ OpenAI TTS API integration (tts-1-1106, alloy voice)
- ✅ Server-side filesystem cache (`./cache/tts/`)
- ✅ Postgres-backed LRU tracking (`audio_cache` table)
- ✅ Automatic cache cleanup at 500MB threshold
- ✅ Frontend integration with Web Speech API fallback
- ✅ Comprehensive test coverage
- ✅ Documentation and deployment guides

**Total Tasks:** 14
**Estimated Implementation Time:** 3-4 hours (with TDD approach)
